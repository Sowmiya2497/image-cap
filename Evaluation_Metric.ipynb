{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Evaluation_Metric.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.15"},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"cell_type":"code","metadata":{"id":"J9QcbAuQ0dh6","colab_type":"code","colab":{}},"source":["import json\n","import time\n","import datetime\n","import numpy as np\n","import code\n","import os\n","import cPickle as pickle\n","import math\n","import scipy.io\n","import matplotlib.pyplot  as plt\n","import matplotlib.image as mpimg\n","from IPython import get_ipython\n","ipy = get_ipython()\n","if ipy is not None:\n","    ipy.run_line_magic('matplotlib', 'inline')\n","from IPython.display import display,Image\n","#from PIL import Image\n","\n","\n","\n","from imagernn.solver import Solver\n","#from imagernn.imagernn_utils import eval_split\n","from imagernn.generic_batch_generator import GenericBatchGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aGi1e7-00diH","colab_type":"text"},"source":["## Metrics"]},{"cell_type":"code","metadata":{"id":"KEeYQ5f60diJ","colab_type":"code","colab":{}},"source":["from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n","from pycocoevalcap.bleu.bleu import Bleu\n","from pycocoevalcap.meteor.meteor import Meteor\n","from pycocoevalcap.rouge.rouge import Rouge\n","from pycocoevalcap.cider.cider import Cider\n","\n","class COCOEvalCap:\n","    def __init__(self,images,gts,res):\n","        self.evalImgs = []\n","        self.eval = {}\n","        self.imgToEval = {}\n","        self.params = {'image_id': images}\n","        self.gts = gts\n","        self.res = res\n","\n","    def evaluate(self):\n","        imgIds = self.params['image_id']\n","        #print imgIds\n","        gts = self.gts\n","        res = self.res\n","\n","        # =================================================\n","        # Set up scorers\n","        # =================================================\n","        print 'tokenization...'\n","        tokenizer = PTBTokenizer()\n","        gts  = tokenizer.tokenize(gts)\n","        res = tokenizer.tokenize(res)\n","\n","        # =================================================\n","        # Set up scorers\n","        # =================================================\n","        print 'setting up scorers...'\n","        scorers = [\n","            (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n","            (Meteor(),\"METEOR\"),\n","            (Rouge(), \"ROUGE_L\"),\n","            (Cider(), \"CIDEr\")\n","        ]\n","\n","        # =================================================\n","        # Compute scores\n","        # =================================================\n","        eval = {}\n","        for scorer, method in scorers:\n","            print 'computing %s score...'%(scorer.method())\n","            score, scores = scorer.compute_score(gts, res)\n","            if type(method) == list:\n","                for sc, scs, m in zip(score, scores, method):\n","                    self.setEval(sc, m)\n","                    self.setImgToEvalImgs(scs, imgIds, m)\n","                    print \"%s: %0.3f\"%(m, sc)\n","            else:\n","                self.setEval(score, method)\n","                self.setImgToEvalImgs(scores, imgIds, method)\n","                print \"%s: %0.3f\"%(method, score)\n","        self.setEvalImgs()\n","\n","    def setEval(self, score, method):\n","        self.eval[method] = score\n","\n","    def setImgToEvalImgs(self, scores, imgIds, method):\n","        for imgId, score in zip(imgIds, scores):\n","            if not imgId in self.imgToEval:\n","                self.imgToEval[imgId] = {}\n","                self.imgToEval[imgId][\"image_id\"] = imgId\n","            self.imgToEval[imgId][method] = score\n","\n","    def setEvalImgs(self):\n","        self.evalImgs = [eval for imgId, eval in self.imgToEval.items()]\n","\n","def calculate_metrics(rng,datasetGTS,datasetRES,train_set,test_set):\n","    imgIds = rng\n","    gts = {}\n","    res = {}\n","\n","    imgToAnnsGTS = {ann['image_id']: [] for ann in datasetGTS['annotations']}\n","    for ann in datasetGTS['annotations']:\n","        imgToAnnsGTS[ann['image_id']] += [ann]\n","\n","    imgToAnnsRES = {ann['image_id']: [] for ann in datasetRES['annotations']}\n","    for ann in datasetRES['annotations']:\n","        imgToAnnsRES[ann['image_id']] += [ann]\n","        \n","        \n","    if train_set == 0 and test_set == 1:\n","        for imgId in range(0,1590):\n","            gts[imgId] = imgToAnnsGTS[imgId]\n","            res[imgId] = imgToAnnsRES[imgId]\n","    else:\n","        for imgId in range(0,5999):\n","            gts[imgId] = imgToAnnsGTS[imgId]\n","            res[imgId] = imgToAnnsRES[imgId]\n","\n","    evalObj = COCOEvalCap(imgIds,gts,res)\n","    evalObj.evaluate()\n","    return evalObj.eval"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cm9j-vL00diS","colab_type":"code","colab":{},"outputId":"840a113b-bafe-41b3-9f15-58af6f926e9e"},"source":["train_set = 0\n","test_set = 0\n","parent = os.getcwd()\n","dataset_path = parent + \"/data/flickr8k/dataset.json\"\n","img_path = parent +\"/data/flickr8k/Flicker8k_Dataset\"\n","\n","data = json.load(open(dataset_path,'r'))\n","# load the features for all images\n","features_path = parent + \"/data/flickr8k/vgg_feats.mat\"\n","features_struct = scipy.io.loadmat(features_path)\n","features = features_struct['feats'] # this is a 4096 x N numpy array of features\n","features = features.T\n","D,N = features.shape\n","print 'features.shape:',features.shape\n","print 'image id:',features_struct.keys()\n","BatchGenerator = GenericBatchGenerator()\n","\n","datasetGTS = {}\n","datasetGTS['annotations'] = []\n","datasetRES = {}\n","datasetRES['annotations'] = []\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["features.shape: (4096, 8091)\n","image id: ['__version__', '__header__', 'feats', '__globals__']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VNtA32yc0dii","colab_type":"text"},"source":["## Evaluation metric on model trained on 6000 images"]},{"cell_type":"markdown","metadata":{"id":"nXqhtXqm0dil","colab_type":"text"},"source":["### Metric on unweighted"]},{"cell_type":"markdown","metadata":{"id":"DDPPuuNU0din","colab_type":"text"},"source":["### For training data (0-6000 images)"]},{"cell_type":"code","metadata":{"id":"3QyRB95t0dip","colab_type":"code","colab":{},"outputId":"3cad636f-2b66-4cd1-c547-32ca314f5f97"},"source":["checkpoint_path = parent + \"/cv/model_checkpoint_flickr8k_7966c3c38f83_baseline_7395.00.p\"\n","print 'loading checkpoint %s' % (checkpoint_path, )\n","checkpoint = pickle.load(open(checkpoint_path, 'rb'))\n","checkpoint_params = checkpoint['params']\n","dataset = checkpoint_params['dataset']\n","model = checkpoint['model']\n","misc = {}\n","misc['wordtoix'] = checkpoint['wordtoix']\n","ixtoword = checkpoint['ixtoword']\n","\n","clearValues()\n","\n","for i in range(0,6000):\n","    img = {}\n","    img['feat'] = features[:, i]\n","    kwparams = { 'beam_size' : 1 }\n","    Ys = BatchGenerator.predict([{'image':img}], model, checkpoint_params, **kwparams)\n","    img_blob = {}\n","    top_predictions = Ys[0] # take predictions for the first (and only) image we passed in\n","    top_prediction = top_predictions[0] # these are sorted with highest on top\n","    candidate = ' '.join([str(ixtoword[ix]) for ix in top_prediction[1] if ix > 0]) \n","    gtsobj = {}\n","    gtsobj['image_id'] = i\n","    gtsobj['caption'] = data['images'][i]['sentences'][0]['raw']\n","    datasetGTS['annotations'].append(gtsobj)\n","    \n","    resobj = {}\n","    resobj['image_id'] = i\n","    resobj['caption'] = candidate\n","    datasetRES['annotations'].append(resobj)\n","    \n","rng = range(6000)\n","train_set = 1\n","test_set = 0\n","print calculate_metrics(rng,datasetGTS,datasetRES,train_set,test_set)\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading checkpoint /home/sakthi/image-cap/cv/model_checkpoint_flickr8k_7966c3c38f83_baseline_7395.00.p\n","tokenization...\n","setting up scorers...\n","computing Bleu score...\n","{'reflen': 66638, 'guess': [67839, 61840, 55841, 49842], 'testlen': 67839, 'correct': [20081, 4986, 1466, 545]}\n","ratio: 1.01802274978\n","Bleu_1: 0.296\n","Bleu_2: 0.154\n","Bleu_3: 0.086\n","Bleu_4: 0.051\n","computing METEOR score...\n","METEOR: 0.109\n","computing Rouge score...\n","ROUGE_L: 0.286\n","computing CIDEr score...\n","CIDEr: 0.285\n","{'CIDEr': 0.2848574737088937, 'Bleu_4': 0.051161424620386864, 'Bleu_3': 0.08557032045771909, 'Bleu_2': 0.1544878559802474, 'Bleu_1': 0.29600966995385697, 'ROUGE_L': 0.28550485692732097, 'METEOR': 0.10916282499921855}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IDDX5TOs0di2","colab_type":"text"},"source":["### For test data 1591 images (6500 - 8091)"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"nPw0hL-F0di4","colab_type":"code","colab":{},"outputId":"8e9f9487-5c20-4d7a-ba94-ad35caeea23b"},"source":["checkpoint_path = parent+ \"/cv/model_checkpoint_flickr8k_7966c3c38f83_baseline_7395.00.p\"\n","print 'loading checkpoint %s' % (checkpoint_path, )\n","checkpoint = pickle.load(open(checkpoint_path, 'rb'))\n","checkpoint_params = checkpoint['params']\n","dataset = checkpoint_params['dataset']\n","model = checkpoint['model']\n","misc = {}\n","misc['wordtoix'] = checkpoint['wordtoix']\n","ixtoword = checkpoint['ixtoword']\n","\n","\n","datasetGTS = {}\n","datasetGTS['annotations'] = []\n","datasetRES = {}\n","datasetRES['annotations'] = []\n","\n","for i in range(6500,8091):\n","    img = {}\n","    img['feat'] = features[:, i]\n","    kwparams = { 'beam_size' : 1 }\n","    Ys = BatchGenerator.predict([{'image':img}], model, checkpoint_params, **kwparams)\n","    img_blob = {}\n","    top_predictions = Ys[0] # take predictions for the first (and only) image we passed in\n","    top_prediction = top_predictions[0] # these are sorted with highest on top\n","    candidate = ' '.join([str(ixtoword[ix]) for ix in top_prediction[1] if ix > 0]) \n","    gtsobj = {}\n","    gtsobj['image_id'] = i-6500\n","    gtsobj['caption'] = data['images'][i]['sentences'][0]['raw']\n","    datasetGTS['annotations'].append(gtsobj)\n","    \n","    resobj = {}\n","    resobj['image_id'] = i-6500\n","    resobj['caption'] = candidate\n","    datasetRES['annotations'].append(resobj)\n","    \n","rng = range(1591)\n","train_set = 0\n","test_set = 1\n","print calculate_metrics(rng,datasetGTS,datasetRES,train_set,test_set)\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading checkpoint /home/sakthi/image-cap/cv/model_checkpoint_flickr8k_7966c3c38f83_baseline_7395.00.p\n","tokenization...\n","setting up scorers...\n","computing Bleu score...\n","{'reflen': 17717, 'guess': [17758, 16168, 14578, 12988], 'testlen': 17758, 'correct': [5310, 1282, 376, 140]}\n","ratio: 1.00231416154\n","Bleu_1: 0.299\n","Bleu_2: 0.154\n","Bleu_3: 0.085\n","Bleu_4: 0.051\n","computing METEOR score...\n","METEOR: 0.108\n","computing Rouge score...\n","ROUGE_L: 0.287\n","computing CIDEr score...\n","CIDEr: 0.300\n","{'CIDEr': 0.3003102906039707, 'Bleu_4': 0.050670123430397895, 'Bleu_3': 0.0848803896147402, 'Bleu_2': 0.15398063172774473, 'Bleu_1': 0.299020159927903, 'ROUGE_L': 0.28745549917612734, 'METEOR': 0.1084317376274938}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dp8M2L3f0djG","colab_type":"text"},"source":["### Metrics for weighted"]},{"cell_type":"markdown","metadata":{"id":"-7VGKzq90djJ","colab_type":"text"},"source":["### For training data (0-6000 images)"]},{"cell_type":"code","metadata":{"id":"Y1PXM1pd0djM","colab_type":"code","colab":{},"outputId":"3e8b4b88-cb34-465b-9f4a-3db3cfa7a304"},"source":["checkpoint_path = parent + \"/cv/model_checkpoint_flickr8k_ba0af9c36d3f_baseline_7395.00.p\"\n","print 'loading checkpoint %s' % (checkpoint_path, )\n","checkpoint = pickle.load(open(checkpoint_path, 'rb'))\n","checkpoint_params = checkpoint['params']\n","dataset = checkpoint_params['dataset']\n","model = checkpoint['model']\n","misc = {}\n","misc['wordtoix'] = checkpoint['wordtoix']\n","ixtoword = checkpoint['ixtoword']\n","\n","\n","datasetGTS = {}\n","datasetGTS['annotations'] = []\n","datasetRES = {}\n","datasetRES['annotations'] = []\n","\n","for i in range(0,6000):\n","    img = {}\n","    img['feat'] = features[:, i]\n","    kwparams = { 'beam_size' : 1 }\n","    Ys = BatchGenerator.predict([{'image':img}], model, checkpoint_params, **kwparams)\n","    img_blob = {}\n","    top_predictions = Ys[0] # take predictions for the first (and only) image we passed in\n","    top_prediction = top_predictions[0] # these are sorted with highest on top\n","    candidate = ' '.join([str(ixtoword[ix]) for ix in top_prediction[1] if ix > 0]) \n","    gtsobj = {}\n","    gtsobj['image_id'] = i\n","    gtsobj['caption'] = data['images'][i]['sentences'][0]['raw']\n","    datasetGTS['annotations'].append(gtsobj)\n","    \n","    resobj = {}\n","    resobj['image_id'] = i\n","    resobj['caption'] = candidate\n","    datasetRES['annotations'].append(resobj)\n","    \n","rng = range(6000)\n","train_set = 1\n","test_set = 0\n","print calculate_metrics(rng,datasetGTS,datasetRES,train_set,test_set)\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading checkpoint /home/sakthi/image-cap/cv/model_checkpoint_flickr8k_ba0af9c36d3f_baseline_7395.00.p\n","features.shape: (4096, 8091)\n","image id: ['__version__', '__header__', 'feats', '__globals__']\n","tokenization...\n","setting up scorers...\n","computing Bleu score...\n","{'reflen': 66647, 'guess': [71689, 65689, 59689, 53689], 'testlen': 71689, 'correct': [21061, 5741, 1864, 653]}\n","ratio: 1.07565231743\n","Bleu_1: 0.294\n","Bleu_2: 0.160\n","Bleu_3: 0.093\n","Bleu_4: 0.056\n","computing METEOR score...\n","METEOR: 0.117\n","computing Rouge score...\n","ROUGE_L: 0.296\n","computing CIDEr score...\n","CIDEr: 0.333\n","{'CIDEr': 0.3325606807259991, 'Bleu_4': 0.055882420422674786, 'Bleu_3': 0.09290184143523018, 'Bleu_2': 0.1602362162015724, 'Bleu_1': 0.29378286766449113, 'ROUGE_L': 0.2957046114358279, 'METEOR': 0.11692933739288391}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UEFj9Nzj0djZ","colab_type":"text"},"source":["### For test data 1591 images (6500 - 8091)"]},{"cell_type":"code","metadata":{"id":"w_wiZReW0djf","colab_type":"code","colab":{},"outputId":"45ce056d-2069-4c90-a798-2e12c2a71218"},"source":["checkpoint_path = parent + \"/cv/model_checkpoint_flickr8k_ba0af9c36d3f_baseline_7395.00.p\"\n","print 'loading checkpoint %s' % (checkpoint_path, )\n","checkpoint = pickle.load(open(checkpoint_path, 'rb'))\n","checkpoint_params = checkpoint['params']\n","dataset = checkpoint_params['dataset']\n","model = checkpoint['model']\n","misc = {}\n","misc['wordtoix'] = checkpoint['wordtoix']\n","ixtoword = checkpoint['ixtoword']\n","\n","datasetGTS = {}\n","datasetGTS['annotations'] = []\n","datasetRES = {}\n","datasetRES['annotations'] = []\n","\n","for i in range(6500,8091):\n","    img = {}\n","    img['feat'] = features[:, i]\n","    kwparams = { 'beam_size' : 1 }\n","    Ys = BatchGenerator.predict([{'image':img}], model, checkpoint_params, **kwparams)\n","    img_blob = {}\n","    top_predictions = Ys[0] # take predictions for the first (and only) image we passed in\n","    top_prediction = top_predictions[0] # these are sorted with highest on top\n","    candidate = ' '.join([str(ixtoword[ix]) for ix in top_prediction[1] if ix > 0]) \n","    gtsobj = {}\n","    gtsobj['image_id'] = i-6500\n","    gtsobj['caption'] = data['images'][i]['sentences'][0]['raw']\n","    datasetGTS['annotations'].append(gtsobj)\n","    \n","    resobj = {}\n","    resobj['image_id'] = i-6500\n","    resobj['caption'] = candidate\n","    datasetRES['annotations'].append(resobj)\n","    \n","rng = range(1591)\n","train_set = 0\n","test_set = 1\n","print calculate_metrics(rng,datasetGTS,datasetRES,train_set,test_set)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading checkpoint /home/sakthi/image-cap/cv/model_checkpoint_flickr8k_ba0af9c36d3f_baseline_7395.00.p\n","features.shape: (4096, 8091)\n","image id: ['__version__', '__header__', 'feats', '__globals__']\n"],"name":"stdout"},{"output_type":"stream","text":["imagernn/lstm_generator.py:207: RuntimeWarning: overflow encountered in exp\n","  IFOGf[t,:3*d] = 1.0/(1.0+np.exp(-IFOG[t,:3*d]))\n"],"name":"stderr"},{"output_type":"stream","text":["tokenization...\n","setting up scorers...\n","computing Bleu score...\n","{'reflen': 17717, 'guess': [18700, 17110, 15520, 13930], 'testlen': 18700, 'correct': [5488, 1439, 464, 160]}\n","ratio: 1.05548343399\n","Bleu_1: 0.293\n","Bleu_2: 0.157\n","Bleu_3: 0.090\n","Bleu_4: 0.054\n","computing METEOR score...\n","METEOR: 0.115\n","computing Rouge score...\n","ROUGE_L: 0.292\n","computing CIDEr score...\n","CIDEr: 0.340\n","{'CIDEr': 0.3399695427417475, 'Bleu_4': 0.05395660337999134, 'Bleu_3': 0.09036560933736541, 'Bleu_2': 0.15710559081758674, 'Bleu_1': 0.2934759358288613, 'ROUGE_L': 0.292373978229879, 'METEOR': 0.11460105656257771}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"csqvCuQp0dju","colab_type":"text"},"source":["## Metric for weighting strategy 2 trained on 6000 images"]},{"cell_type":"markdown","metadata":{"id":"POWIq9n80djz","colab_type":"text"},"source":["### For training data (0-6000 images)"]},{"cell_type":"code","metadata":{"id":"fqPBTzZ50dj1","colab_type":"code","colab":{},"outputId":"bce1c3d9-6725-4e93-f2c4-e82a14c79346"},"source":["checkpoint_path = parent + \"/cv/model_checkpoint_flickr8k_2e3bd92f6ccb_baseline_7395.00.p\"\n","print 'loading checkpoint %s' % (checkpoint_path, )\n","checkpoint = pickle.load(open(checkpoint_path, 'rb'))\n","checkpoint_params = checkpoint['params']\n","dataset = checkpoint_params['dataset']\n","model = checkpoint['model']\n","misc = {}\n","misc['wordtoix'] = checkpoint['wordtoix']\n","ixtoword = checkpoint['ixtoword']\n","\n","datasetGTS = {}\n","datasetGTS['annotations'] = []\n","datasetRES = {}\n","datasetRES['annotations'] = []\n","\n","for i in range(0,6000):\n","    img = {}\n","    img['feat'] = features[:, i]\n","    kwparams = { 'beam_size' : 1 }\n","    Ys = BatchGenerator.predict([{'image':img}], model, checkpoint_params, **kwparams)\n","    img_blob = {}\n","    top_predictions = Ys[0] # take predictions for the first (and only) image we passed in\n","    top_prediction = top_predictions[0] # these are sorted with highest on top\n","    candidate = ' '.join([str(ixtoword[ix]) for ix in top_prediction[1] if ix > 0]) \n","    gtsobj = {}\n","    gtsobj['image_id'] = i\n","    gtsobj['caption'] = data['images'][i]['sentences'][0]['raw']\n","    datasetGTS['annotations'].append(gtsobj)\n","    \n","    resobj = {}\n","    resobj['image_id'] = i\n","    resobj['caption'] = candidate\n","    datasetRES['annotations'].append(resobj)\n","    \n","rng = range(6000)\n","train_set = 1\n","test_set = 0\n","print calculate_metrics(rng,datasetGTS,datasetRES,train_set,test_set)\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading checkpoint /home/sakthi/image-cap/cv/model_checkpoint_flickr8k_2e3bd92f6ccb_baseline_7395.00.p\n","features.shape: (4096, 8091)\n","image id: ['__version__', '__header__', 'feats', '__globals__']\n","tokenization...\n","setting up scorers...\n","computing Bleu score...\n","{'reflen': 66647, 'guess': [69538, 63538, 57538, 51538], 'testlen': 69538, 'correct': [21380, 5811, 1884, 744]}\n","ratio: 1.04337779645\n","Bleu_1: 0.307\n","Bleu_2: 0.168\n","Bleu_3: 0.097\n","Bleu_4: 0.060\n","computing METEOR score...\n","METEOR: 0.119\n","computing Rouge score...\n","ROUGE_L: 0.298\n","computing CIDEr score...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x7yILkiS0dkH","colab_type":"text"},"source":["### For test data 1591 images (6500 - 8091)"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"5IW66nI70dkM","colab_type":"code","colab":{},"outputId":"143094ac-bef9-406f-94c0-2bff11196572"},"source":["checkpoint_path = parent + \"/cv/model_checkpoint_flickr8k_2e3bd92f6ccb_baseline_7395.00.p\"\n","print 'loading checkpoint %s' % (checkpoint_path, )\n","checkpoint = pickle.load(open(checkpoint_path, 'rb'))\n","checkpoint_params = checkpoint['params']\n","dataset = checkpoint_params['dataset']\n","model = checkpoint['model']\n","misc = {}\n","misc['wordtoix'] = checkpoint['wordtoix']\n","ixtoword = checkpoint['ixtoword']\n","\n","\n","datasetGTS = {}\n","datasetGTS['annotations'] = []\n","datasetRES = {}\n","datasetRES['annotations'] = []\n","\n","for i in range(6500,8091):\n","    img = {}\n","    img['feat'] = features[:, i]\n","    kwparams = { 'beam_size' : 1 }\n","    Ys = BatchGenerator.predict([{'image':img}], model, checkpoint_params, **kwparams)\n","    img_blob = {}\n","    top_predictions = Ys[0] # take predictions for the first (and only) image we passed in\n","    top_prediction = top_predictions[0] # these are sorted with highest on top\n","    candidate = ' '.join([str(ixtoword[ix]) for ix in top_prediction[1] if ix > 0]) \n","    gtsobj = {}\n","    gtsobj['image_id'] = i-6500\n","    gtsobj['caption'] = data['images'][i]['sentences'][0]['raw']\n","    datasetGTS['annotations'].append(gtsobj)\n","    \n","    resobj = {}\n","    resobj['image_id'] = i-6500\n","    resobj['caption'] = candidate\n","    datasetRES['annotations'].append(resobj)\n","    \n","rng = range(1591)\n","train_set = 0\n","test_set = 1\n","print calculate_metrics(rng,datasetGTS,datasetRES,train_set,test_set)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading checkpoint /home/sakthi/image-cap/cv/model_checkpoint_flickr8k_2e3bd92f6ccb_baseline_7395.00.p\n","features.shape: (4096, 8091)\n","image id: ['__version__', '__header__', 'feats', '__globals__']\n","tokenization...\n","setting up scorers...\n","computing Bleu score...\n","{'reflen': 17717, 'guess': [18229, 16639, 15049, 13459], 'testlen': 18229, 'correct': [5584, 1422, 452, 167]}\n","ratio: 1.02889879776\n","Bleu_1: 0.306\n","Bleu_2: 0.162\n","Bleu_3: 0.092\n","Bleu_4: 0.056\n","computing METEOR score...\n","METEOR: 0.115\n","computing Rouge score...\n","ROUGE_L: 0.296\n","computing CIDEr score...\n","CIDEr: 0.323\n","{'CIDEr': 0.3225420725729645, 'Bleu_4': 0.05588848697879914, 'Bleu_3': 0.09229862770371737, 'Bleu_2': 0.16179960970427323, 'Bleu_1': 0.30632508640077316, 'ROUGE_L': 0.2957793647161788, 'METEOR': 0.11507930399416517}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JAP8j5b50dkf","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HslRvQ2B0dks","colab_type":"code","colab":{}},"source":["train_table = pd.DataFrame({\"Metrics\":[\"BLEU-1\",\"BLEU-2\",\"BLEU-3\",\"BLEU-4\",\"METEOR\",\"ROGUE_L\",\"CIDEr\"],\n","                         \"Vanilla Model\":[29.6,15.4,8.6,5.1,10.9,28.6,28.5],\n","                         \"Weighting strategy 1\":[29.4,16,9.3,5.6,11.7,29.6,33.3],\n","                         \"Weighting strategy 2\":[30.7,16.8,9.7,6,11.9,29.8,34]})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"13MURKHW0dk6","colab_type":"code","colab":{}},"source":["test_table = pd.DataFrame({\"Metrics\":[\"BLEU-1\",\"BLEU-2\",\"BLEU-3\",\"BLEU-4\",\"METEOR\",\"ROGUE_L\",\"CIDEr\"],\n","                         \"Vanilla Model\":[23.5,17.8,11.9,1.82e-3,14.9,26.8,47.1],\n","                         \"Weighting strategy 1\":[30.4,24.1,18.3,2.44e-3,17.5,28.4,62.1],\n","                         \"Weighting strategy 2\":[27.8,18.6,13.5,2.13e-3,14.2,34.4,144.6]})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3V4a-Vc0dlF","colab_type":"code","colab":{},"outputId":"764af87f-b7ec-49d6-ad88-247aa98e29b4"},"source":["print \"training result\"\n","train_table"],"execution_count":0,"outputs":[{"output_type":"stream","text":["training result\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Metrics</th>\n","      <th>Vanilla Model</th>\n","      <th>Weighting strategy 1</th>\n","      <th>Weighting strategy 2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BLEU-1</td>\n","      <td>29.6</td>\n","      <td>29.4</td>\n","      <td>30.7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BLEU-2</td>\n","      <td>15.4</td>\n","      <td>16.0</td>\n","      <td>16.8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BLEU-3</td>\n","      <td>8.6</td>\n","      <td>9.3</td>\n","      <td>9.7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BLEU-4</td>\n","      <td>5.1</td>\n","      <td>5.6</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>METEOR</td>\n","      <td>10.9</td>\n","      <td>11.7</td>\n","      <td>11.9</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ROGUE_L</td>\n","      <td>28.6</td>\n","      <td>29.6</td>\n","      <td>29.8</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CIDEr</td>\n","      <td>28.5</td>\n","      <td>33.3</td>\n","      <td>34.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Metrics  Vanilla Model  Weighting strategy 1  Weighting strategy 2\n","0   BLEU-1           29.6                  29.4                  30.7\n","1   BLEU-2           15.4                  16.0                  16.8\n","2   BLEU-3            8.6                   9.3                   9.7\n","3   BLEU-4            5.1                   5.6                   6.0\n","4   METEOR           10.9                  11.7                  11.9\n","5  ROGUE_L           28.6                  29.6                  29.8\n","6    CIDEr           28.5                  33.3                  34.0"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"y1Mqs89N0dlh","colab_type":"code","colab":{},"outputId":"73e8cc5f-8173-45a3-e4e6-b7e5770256d0"},"source":["print \"testing result\"\n","test_table"],"execution_count":0,"outputs":[{"output_type":"stream","text":["testing result\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Metrics</th>\n","      <th>Vanilla Model</th>\n","      <th>Weighting strategy 1</th>\n","      <th>Weighting strategy 2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BLEU-1</td>\n","      <td>23.50000</td>\n","      <td>30.40000</td>\n","      <td>27.80000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BLEU-2</td>\n","      <td>17.80000</td>\n","      <td>24.10000</td>\n","      <td>18.60000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BLEU-3</td>\n","      <td>11.90000</td>\n","      <td>18.30000</td>\n","      <td>13.50000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BLEU-4</td>\n","      <td>0.00182</td>\n","      <td>0.00244</td>\n","      <td>0.00213</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>METEOR</td>\n","      <td>14.90000</td>\n","      <td>17.50000</td>\n","      <td>14.20000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ROGUE_L</td>\n","      <td>26.80000</td>\n","      <td>28.40000</td>\n","      <td>34.40000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CIDEr</td>\n","      <td>47.10000</td>\n","      <td>62.10000</td>\n","      <td>144.60000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Metrics  Vanilla Model  Weighting strategy 1  Weighting strategy 2\n","0   BLEU-1       23.50000              30.40000              27.80000\n","1   BLEU-2       17.80000              24.10000              18.60000\n","2   BLEU-3       11.90000              18.30000              13.50000\n","3   BLEU-4        0.00182               0.00244               0.00213\n","4   METEOR       14.90000              17.50000              14.20000\n","5  ROGUE_L       26.80000              28.40000              34.40000\n","6    CIDEr       47.10000              62.10000             144.60000"]},"metadata":{"tags":[]},"execution_count":22}]}]}