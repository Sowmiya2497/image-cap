  
import numpy as np
import math
import json
import re
import nltk
from numpy import linalg as la

def featureSubtraction(a,b):
    """ subtracts two vectors and returns norm of result """
    subResult = np.subtract(a,b)
    normResult = math.pow(la.norm(subResult),2)
    #print 'subtracted features',normResult
    return normResult

def calcSigma(data):
    """ returns average distance of each two images in a dataset """
    avgDist = 0
    numPairs = 0
    i = 0
    for i in range(0,len(data)) :
        imgA = data[i]
        for j in range(i+1,len(data)):
            numPairs += 1
            imgB = data[j]
            #print 'start:'
            dist = featureSubtraction(imgA['feats'], imgB['feats'])

            avgDist += dist
    sigma = avgDist/numPairs
    print 'sigma:',sigma
    print 'numPairs:',numPairs
    return sigma # 9769.6811

def getImageIds(word,data):
    """returns list of image whose captions contain this word""" ##doubt - what happens if word is not in vocabulary? find out - how testing
    GSi = []               ##works. will a word never seen before be generated by the model?
    for img in data:       ##i dont think this is possible. If its not, there will be no problem with unknown
        if word in img['tokens']:  ##word weight calculation.
            GSi.append(img)

    #print 'Gsi',GSi
    return GSi

def calculateWeights(wordtoixdict, ixtoworddict, data):
    """ calculates weight of each word relative to the image it appears in """
    print 'Starting weight calculation......'
    weightJsonData=[]
    #sigma = calcSigma(data)
    sigma = 2518.03392025
    index = 0
    print 'data.len',len(data)
    for img in data :
        print index
        index+=1
        #if img['imgid'] == 1241:
            #print 'Feats :', img['feats'] # Testing if feats has been copied correctly
        for Si in img['tokens']:
            # get list of image ids that also contain this word
            GSi = getImageIds(Si,data)
            Ksig=0
            for im in GSi:
                subtractedFeats = featureSubtraction(img['feats'],im['feats']) # subtract I - Ij
                val = -(subtractedFeats/sigma)
                Ksigi=math.exp(val)
                #print 'Ksigi',Ksigi
                Ksig+=Ksigi
                #print 'Ksig',Ksig
            weight=Ksig/len(GSi)
            img['tokenWeight'].append(weight)
        wtjson = {}
        wtjson['imgid'] = img['imgid']
        #wtjson['feats'] = img['feats']
        wtjson['filename'] = img['filename']
        wtjson['tokens'] = img['tokens']
        wtjson['tokenWeight'] = img['tokenWeight']

        weightJsonData.append(wtjson)
    with open('weightData.json', 'w') as outfile:
        json.dump(weightJsonData, outfile)

    #print data
    #return data

def weightCalculationMethodSec():
    with open("weightData.json",'r') as f:
        data = json.load(f)
    reN = re.compile("^N")
    reV = re.compile("^V")
    reP = re.compile("^I")
    newData = []
    index = 0
    for img in data:
        print 'index:',index
        index = index + 1
        #print 'tokens',img['tokens']
        #for i in range(len(img['tokens'])):
        #print 'tokens:',str(img['tokens'][i])
        tag = nltk.pos_tag(img['tokens'])
        #print 'tag',tag
        
        for i in range(len(tag)):
            if (re.search(reN,tag[i][1])):
                #print 'words',tag[i][0]
                #print 'weight:%f after updation: ' %(img['tokenWeight'][i])
                img['tokenWeight'][i] = img['tokenWeight'][i] * 1.1
                #print 'weight:',img['tokenWeight'][i]
            elif(re.search(reV,tag[i][1])):
                img['tokenWeight'][i] = img['tokenWeight'][i] * 1.05
            elif(re.search(reP,tag[i][1])):
                img['tokenWeight'][i] = img['tokenWeight'][i] * 0.8
        
        wtjson = {}
        wtjson['imgid'] = img['imgid']
        #wtjson['feats'] = img['feats']
        wtjson['filename'] = img['filename']
        wtjson['tokens'] = img['tokens']
        wtjson['tokenWeight'] = img['tokenWeight']
        
        newData.append(wtjson)
    with open('weightMethod_2.json', 'w') as outfile:
        json.dump(newData, outfile)
            
        '''
        if(re.search(reN,tag[1])):
            print 'weight;%f after updation: ' %(img['tokenWeight'][img['tokens'].index(i)])
        '''
    
    print 'out of for'
      
def getWeightsMethod1():
    with open("weightData.json",'r') as f:
        data = json.load(f)
    return data

def getWeightsMethod2():
    with open("weightMethod_2.json",'r') as f:
        data = json.load(f)
    return data

def returnWeights(imgid,gtix,ixtoword,data):
  for img in data:
    if img['imgid'] == imgid :
      wordWeights = []
      #print 'gtix:',gtix
      for idx in gtix :
        word = ixtoword[idx]
        #print 'ixtoword[idx]:',word
        if word == '.':
          wordWeights.append(1)
        else:
          position = img['tokens'].index(word) ##return position of word from list of words in caption
          wt = img['tokenWeight'][position]
          wordWeights.append(wt)
  return wordWeights
